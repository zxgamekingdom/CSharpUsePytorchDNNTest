import array
import ctypes
import time
import numpy
import torch
from nets.deeplabv3_plus import DeepLab

def init_model(model_path):
	num_classes = 3
	backbone = 'mobilenet'
	downsample_factor = 8
	model = DeepLab(num_classes=num_classes,
					backbone=backbone,
					downsample_factor=downsample_factor,
					pretrained=False)
	model.load_state_dict(torch.load(model_path))
	model = model.cuda()
	model.eval()
	in_value = torch.randn(6, 3, 512, 512).cuda()
	with torch.no_grad():
		for i in range(10):
			_ = model(in_value)
	return model

def eval(model: DeepLab, in_ptr: int, out_put_ptr: array.array):
	t1 = time.time()
	# 创建数组指针类型
	arr_type = ctypes.POINTER(ctypes.c_int32 * (6 * 3 * 512 * 512))
	# 读取指针内容
	arr_pointer = ctypes.cast(in_ptr, arr_type)
	# 从指针内容创建numpy
	arr = numpy.frombuffer(arr_pointer.contents, dtype=numpy.int32)
	# shape to 6, 3, 512, 512, dtype to float32
	ts = torch.from_numpy(arr).reshape(6, 3, 512, 512).float().cuda()
	t2 = time.time()
	print(f'local memory to tensor(ms): {(t2 - t1) * 1000}')
	# in_value归一化
	t3 = time.time()
	ts = ts / 255
	t4 = time.time()
	print(f'normalize(ms): {(t4 - t3) * 1000}')
	with torch.no_grad():
		t5 = time.time()
		result = model(ts)
		t6 = time.time()
		print(f'forward(ms): {(t6 - t5) * 1000}')
	t7 = time.time()
	for i in range(6):
		t71 = time.time()
		r = result[i]
		permute = r.permute(1, 2, 0)
		softmax = torch.nn.functional.softmax(permute, dim=-1)
		argmax = torch.argmax(softmax, dim=-1)
		cpu = argmax.cpu().byte()
		# 获取tensor指针
		pointer = cpu.data_ptr()
		# 将tensor内容深拷贝到传入的结果指针
		ctypes.memmove(out_put_ptr[i], pointer, 512 * 512)
		t72 = time.time()
		print(f'single post process(ms): {(t72 - t71) * 1000}')
	t8 = time.time()
	print(f'post process(ms): {(t8 - t7) * 1000}')